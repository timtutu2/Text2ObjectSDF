apiVersion: batch/v1
kind: Job
metadata:
  name: textsdf-training4-job
spec:
  backoffLimit: 2  # Retry up to 2 times if the job fails
  ttlSecondsAfterFinished: 86400  # Auto-delete job after 24 hours of completion
  template:
    metadata:
      labels:
        app: textsdf-training4-job
    spec:
      containers:
      - name: gpu-container
        image: timttu/text2objectsdf:v5
        command: ["/bin/bash", "-c"]
        args: [
          "set -e && \
          git config --global credential.helper store && \
          echo \"https://oauth2:${GIT_ACCESS_TOKEN}@github.com\" > ~/.git-credentials && \
          cd /mnt/tim && \
          if [ ! -d text2objectsdf ]; then \
            echo 'Cloning repository...' && \
            git clone https://github.com/timtutu2/Text2ObjectSDF.git text2objectsdf ; \
          else \
            echo 'Repository exists, pulling latest changes...' && \
            cd text2objectsdf && git pull ; \
          fi && \
          pip install --no-cache-dir notebook jupyterlab debugpy ipdb gdown tqdm && \
          cd /mnt/tim/text2objectsdf && \
          export PYTHONPATH=/mnt/tim/text2objectsdf:${PYTHONPATH} && \
          mkdir -p logs && \
          LOGFILE=logs/text2object_$(date +%Y%m%d_%H%M%S).log && \
          echo \"Saving logs to $LOGFILE\" && \
          torchrun --standalone --nnodes=1 --nproc_per_node=4 scripts/train.py \
            --config configs/default.yaml \
            --points-per-batch 4096 \
            --num-workers 2 \
            --grad-accum-steps 8 \
            --amp 2>&1 | tee $LOGFILE && \
          echo \"Training completed. Logs saved to $LOGFILE\""
        ]
        env:
        - name: AUTO_MODE
          value: "true"
        - name: WANDB_API_KEY
          valueFrom:
            secretKeyRef:
              name: wandb-tim-secret 
              key: api_key
        - name: GIT_ACCESS_TOKEN
          valueFrom:
            secretKeyRef:
              name: github--token
              key: GIT_ACCESS_TOKEN
        volumeMounts:
        - mountPath: /mnt
          name: erl-ucsd
        - mountPath: /dev/shm
          name: dshm
        resources:
          limits:
            nvidia.com/gpu: "4"
            memory: "64G"
            cpu: "16"
          requests:
            nvidia.com/gpu: "4"
            memory: "64G"
            cpu: "16"
      restartPolicy: OnFailure  # Retry on failure, but not on success
      affinity:
        nodeAffinity:
          # Hard requirements:
          # 1) exclude known broken nodes
          # 2) allow Turing+ GPUs (2080 and newer); the Docker image already includes sm_75 for tinycudann
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/hostname
                operator: NotIn
                values:
                - "k8s-haosu-04.sdsc.optiputer.net"
                - "ry-gpu-14.sdsc.optiputer.net"
          # Prefer nodes with good network for faster docker image pulls
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: kubernetes.io/hostname
                operator: In
                values:
                - "ry-gpu-01.sdsc.optiputer.net"
                - "ry-gpu-02.sdsc.optiputer.net"
                - "ry-gpu-03.sdsc.optiputer.net"
                - "ry-gpu-04.sdsc.optiputer.net"
                - "ry-gpu-05.sdsc.optiputer.net"
                - "ry-gpu-06.sdsc.optiputer.net"
                - "ry-gpu-07.sdsc.optiputer.net"
                - "ry-gpu-08.sdsc.optiputer.net"
                - "ry-gpu-09.sdsc.optiputer.net"
                - "ry-gpu-10.sdsc.optiputer.net"
                - "ry-gpu-11.sdsc.optiputer.net"
                - "ry-gpu-12.sdsc.optiputer.net"
                - "ry-gpu-13.sdsc.optiputer.net"
                - "ry-gpu-14.sdsc.optiputer.net"
                - "ry-gpu-15.sdsc.optiputer.net"
                - "ry-gpu-16.sdsc.optiputer.net"
                - "k8s-3090-01.calit2.optiputer.net"
                - "k8s-4090-01.calit2.optiputer.net"
                - "k8s-4090-02.calit2.optiputer.net"
          - weight: 50
            preference:
              matchExpressions:
              - key: kubernetes.io/hostname
                operator: In
                values:
                - "k8s-haosu-02.sdsc.optiputer.net"
                - "k8s-haosu-03.sdsc.optiputer.net"
                - "k8s-haosu-04.sdsc.optiputer.net"
                - "k8s-haosu-05.sdsc.optiputer.net"
                - "k8s-haosu-06.sdsc.optiputer.net"
                - "k8s-haosu-07.sdsc.optiputer.net"
                - "k8s-haosu-08.sdsc.optiputer.net"
                - "k8s-haosu-09.sdsc.optiputer.net"
                - "k8s-haosu-10.sdsc.optiputer.net"
                - "k8s-haosu-11.sdsc.optiputer.net"
                - "k8s-haosu-12.sdsc.optiputer.net"
                - "k8s-haosu-13.sdsc.optiputer.net"
                - "k8s-haosu-14.sdsc.optiputer.net"
                - "k8s-haosu-15.sdsc.optiputer.net"
                - "k8s-haosu-16.sdsc.optiputer.net"
                - "k8s-haosu-17.sdsc.optiputer.net"
                - "k8s-haosu-18.sdsc.optiputer.net"
                - "k8s-haosu-19.sdsc.optiputer.net"
                - "k8s-haosu-20.sdsc.optiputer.net"
                - "k8s-haosu-21.sdsc.optiputer.net"
                - "k8s-haosu-22.sdsc.optiputer.net"
                - "k8s-haosu-23.sdsc.optiputer.net"
          - weight: 80
            preference:
              matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - "NVIDIA-A100-80GB-PCIe"
                - "NVIDIA-A100-SXM4-80GB"
                - "NVIDIA-A100-80GB-PCIe-MIG-1g.10gb"
                - "NVIDIA-A100-PCIE-40GB"
                - "NVIDIA-RTX-A6000"
                - "NVIDIA-RTX-A5000"
                - "NVIDIA-GeForce-RTX-4090"
                - "NVIDIA-GeForce-RTX-4080"
                - "NVIDIA-GeForce-RTX-3090-Ti"
                - "NVIDIA-GeForce-RTX-3090"
                - "NVIDIA-GeForce-RTX-3080-Ti"
                - "NVIDIA-GeForce-RTX-3080"
          - weight: 60
            preference:
              matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - "NVIDIA-A40"
                - "Tesla-V100-SXM2-32GB"
                - "Tesla-V100-PCIE-16GB"
          - weight: 50
            preference:
              matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - "NVIDIA-TITAN-RTX"
                - "NVIDIA-GeForce-RTX-2080-Ti"
                - "NVIDIA-TITAN-Xp"
                - "NVIDIA-L40"
                - "NVIDIA-A10"
      volumes:
        - name: erl-ucsd
          persistentVolumeClaim:
            claimName: erl-ucsd
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 8Gi
